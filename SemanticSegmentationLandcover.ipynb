{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSegmentationLandcover.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrTdRjqqEbWSTx0LE9pQa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameerq08/ComputerVision/blob/main/SemanticSegmentationLandcover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFw3BOB3lXtM",
        "outputId": "a7d11c4e-12ee-4788-aaa1-2bf0659a1c9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.2.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRVPP5LBiuG6",
        "outputId": "58f0c3ae-b1ef-4a32-920b-e1edb8e0c35a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import segmentation_models as sm\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_img_dir = \"data/data_for_keras_aug/train_images/train/\"\n",
        "train_mask_dir = \"data/data_for_keras_aug/train_masks/train/\"\n",
        "\n",
        "img_list = os.listdir(train_img_dir)\n",
        "msk_list = os.listdir(train_mask_dir)\n",
        "\n",
        "num_images = len(os.listdir(train_img_dir))\n",
        "\n",
        "\n",
        "img_num = random.randint(0, num_images-1)\n",
        "\n",
        "img_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\n",
        "img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)"
      ],
      "metadata": {
        "id": "F1I0110ui05Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_for_plot)\n",
        "plt.title('Image')\n",
        "plt.subplot(122)\n",
        "plt.imshow(mask_for_plot, cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G0tqClGWi_GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=24\n",
        "batch_size= 16\n",
        "n_classes=4\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "L8mXDT2ljOk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use this to preprocess input for transfer learning\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "#Define a function to perform additional preprocessing after datagen.\n",
        "#For example, scale images, convert masks to categorical, etc. \n",
        "def preprocess_data(img, mask, num_class):\n",
        "    #Scale images\n",
        "    img = scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)\n",
        "    img = preprocess_input(img)  #Preprocess based on the pretrained backbone...\n",
        "    #Convert mask to one-hot\n",
        "    mask = to_categorical(mask, num_class)\n",
        "      \n",
        "    return (img,mask)"
      ],
      "metadata": {
        "id": "KlYRfccHjUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "def trainGenerator(train_img_path, train_mask_path, num_class):\n",
        "    \n",
        "    img_data_gen_args = dict(horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')\n",
        "    \n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "    mask_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "    \n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_img_path,\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    \n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_mask_path,\n",
        "        class_mode = None,\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    \n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    \n",
        "    for (img, mask) in train_generator:\n",
        "        img, mask = preprocess_data(img, mask, num_class)\n",
        "        yield (img, mask)"
      ],
      "metadata": {
        "id": "BoYSjF1QjbDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = \"data/data_for_keras_aug/train_images/\"\n",
        "train_mask_path = \"data/data_for_keras_aug/train_masks/\"\n",
        "train_img_gen = trainGenerator(train_img_path, train_mask_path, num_class=4)\n",
        "\n",
        "val_img_path = \"data/data_for_keras_aug/val_images/\"\n",
        "val_mask_path = \"data/data_for_keras_aug/val_masks/\"\n",
        "val_img_gen = trainGenerator(val_img_path, val_mask_path, num_class=4)"
      ],
      "metadata": {
        "id": "p3NPPAOpjgwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_img_gen.__next__()\n",
        "\n",
        "for i in range(0,3):\n",
        "    image = x[i]\n",
        "    mask = np.argmax(y[i], axis=2)\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "x_val, y_val = val_img_gen.__next__()\n",
        "\n",
        "for i in range(0,3):\n",
        "    image = x_val[i]\n",
        "    mask = np.argmax(y_val[i], axis=2)\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5ttwpvKRjm9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_imgs = len(os.listdir('data/data_for_keras_aug/train_images/train/'))\n",
        "num_val_images = len(os.listdir('data/data_for_keras_aug/val_images/val/'))\n",
        "steps_per_epoch = num_train_imgs//batch_size\n",
        "val_steps_per_epoch = num_val_images//batch_size\n",
        "\n",
        "\n",
        "IMG_HEIGHT = x.shape[1]\n",
        "IMG_WIDTH  = x.shape[2]\n",
        "IMG_CHANNELS = x.shape[3]\n",
        "\n",
        "n_classes=4"
      ],
      "metadata": {
        "id": "fd8kQNMojqOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.Unet(BACKBONE, encoder_weights='imagenet', \n",
        "                input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
        "                classes=n_classes, activation='softmax')\n",
        "model.compile('Adam', loss=sm.losses.categorical_focal_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
        "\n",
        "#Other losses to try: categorical_focal_dice_loss, cce_jaccard_loss, cce_dice_loss, categorical_focal_loss\n",
        "\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "print(model.summary())\n",
        "print(model.input_shape)\n",
        "#Fit the model\n",
        "#history = model.fit(my_generator, validation_data=validation_datagen, steps_per_epoch=len(X_train) // 16, validation_steps=len(X_train) // 16, epochs=100)\n",
        "#Train the model. \n",
        "history=model.fit(train_img_gen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=25,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_gen,\n",
        "          validation_steps=val_steps_per_epoch)\n",
        "\n",
        "model.save('landcover_25_epochs_RESNET_backbone_batch16.hdf5')"
      ],
      "metadata": {
        "id": "dC7E8lbIj5YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['iou_score']\n",
        "val_acc = history.history['val_iou_score']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training IoU')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation IoU')\n",
        "plt.title('Training and validation IoU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V6NJ4Wmnj76z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"landcover_25_epochs_RESNET_backbone_batch16.hdf5\", compile=False)\n",
        "\n",
        "#batch_size=32 #Check IoU for a batch of images\n",
        "\n",
        "#Test generator using validation data.\n",
        "\n",
        "test_image_batch, test_mask_batch = val_img_gen.__next__()\n",
        "\n",
        "#Convert categorical to integer for visualization and IoU calculation\n",
        "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3) \n",
        "test_pred_batch = model.predict(test_image_batch)\n",
        "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n",
        "\n",
        "n_classes = 4\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "j7hiA-dQkCeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_num = random.randint(0, test_image_batch.shape[0]-1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_image_batch[img_num])\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(test_mask_batch_argmax[img_num])\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(test_pred_batch_argmax[img_num])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WcZfyXbJkG1q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}